{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ResNet from scratch.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOtJXYCrec5vWbmJ4b6VM8Y"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"WSKTc3BFwvq0","executionInfo":{"status":"ok","timestamp":1616280870966,"user_tz":420,"elapsed":832,"user":{"displayName":"Ankur Manikandan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh0fa0EuPCtGNgVCRiY6GI5Mx7fAl2Eu7pPVBF4=s64","userId":"06805748719310856295"}}},"source":["import random\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from torchsummary import summary\n","import torchvision.models as models\n","\n","# Assign seed to ensure repeatability\n","SEED = 42\n","random.seed(SEED)\n","np.random.seed(SEED)"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4quDvOZrxW2K"},"source":["# Define Residual Blocks\n","\n","There are two types of residual blocks:\n","- Basic Block. Used for ResNet18 and ResNet34\n","- Bottleneck Block. Used for ResNet50, ResNet101, ResNet152"]},{"cell_type":"code","metadata":{"id":"85VJojt6xSDs","executionInfo":{"status":"ok","timestamp":1616280870971,"user_tz":420,"elapsed":820,"user":{"displayName":"Ankur Manikandan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh0fa0EuPCtGNgVCRiY6GI5Mx7fAl2Eu7pPVBF4=s64","userId":"06805748719310856295"}}},"source":["class BasicBlock(nn.Module):\n","  expansion = 1\n","  def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n","    super().__init__()\n","    # Declare the elements of a basic block\n","    self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3,\n","                           stride=stride, padding=1, bias=False)\n","    self.bn1 = nn.BatchNorm2d(out_channels)\n","    self.act = nn.ReLU(inplace=True)\n","    self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,\n","                           stride=1, padding=1, bias=False)\n","    self.bn2 = nn.BatchNorm2d(out_channels)\n","    self.downsample = downsample\n","\n","  def forward(self, x):\n","\n","    identity_map = x\n","\n","    out = self.conv1(x)\n","    out = self.bn1(out)\n","    out = self.act(out)\n","    out = self.conv2(out)\n","    out = self.bn2(out)\n","    if self.downsample is not None:\n","      identity_map = self.downsample(x)\n","    # Add the identity map to the output of the convolution\n","    out += identity_map\n","    out = self.act(out)\n","\n","    return out"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2PJZuClRx2gV","executionInfo":{"status":"ok","timestamp":1616280870972,"user_tz":420,"elapsed":806,"user":{"displayName":"Ankur Manikandan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh0fa0EuPCtGNgVCRiY6GI5Mx7fAl2Eu7pPVBF4=s64","userId":"06805748719310856295"}},"outputId":"090ce86e-ce2b-4eb5-adb0-0e56244837f3"},"source":["basic_block = BasicBlock(3, 64)\n","basic_block"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BasicBlock(\n","  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (act): ReLU(inplace=True)\n","  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",")"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"o2VsQAObx3FJ","executionInfo":{"status":"ok","timestamp":1616280870973,"user_tz":420,"elapsed":791,"user":{"displayName":"Ankur Manikandan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh0fa0EuPCtGNgVCRiY6GI5Mx7fAl2Eu7pPVBF4=s64","userId":"06805748719310856295"}}},"source":["class BottleneckBlock(nn.Module):\n","  expansion = 4\n","  def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n","    super().__init__()\n","    # Declare the elements of a basic block\n","    self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1,\n","                           stride=stride, bias=False)\n","    self.bn1 = nn.BatchNorm2d(out_channels)\n","    self.act = nn.ReLU(inplace=True)\n","    self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,\n","                           stride=1, padding=1, bias=False)\n","    self.bn2 = nn.BatchNorm2d(out_channels)\n","    self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion, \n","                           kernel_size=1, stride=1, bias=False)\n","    self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n","    self.downsample = downsample\n","\n","  def forward(self, x):\n","\n","    identity_map = x\n","\n","    out = self.conv1(x)\n","    out = self.bn1(out)\n","    out = self.act(out)\n","    out = self.conv2(out)\n","    out = self.bn2(out)\n","    out = self.act(out)\n","    out = self.conv3(out)\n","    out = self.bn3(out)\n","    if self.downsample is not None:\n","      identity_map = self.downsample(x)\n","    # Add the identity map to the output of the convolution\n","    out += identity_map\n","    out = self.act(out)\n","\n","    return out"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O_T4JYY0x66o","executionInfo":{"status":"ok","timestamp":1616280870974,"user_tz":420,"elapsed":777,"user":{"displayName":"Ankur Manikandan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh0fa0EuPCtGNgVCRiY6GI5Mx7fAl2Eu7pPVBF4=s64","userId":"06805748719310856295"}},"outputId":"6c0f7698-aa09-415e-fd6c-1e662866643f"},"source":["bottleneck_block = BottleneckBlock(64, 64)\n","bottleneck_block"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BottleneckBlock(\n","  (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (act): ReLU(inplace=True)\n","  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",")"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"FuNmS0qCyA72"},"source":["# Define ResNet Layers"]},{"cell_type":"code","metadata":{"id":"hYp_5Ooix9t8","executionInfo":{"status":"ok","timestamp":1616280871096,"user_tz":420,"elapsed":884,"user":{"displayName":"Ankur Manikandan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh0fa0EuPCtGNgVCRiY6GI5Mx7fAl2Eu7pPVBF4=s64","userId":"06805748719310856295"}}},"source":["class ResNetLayer(nn.Module):\n","  def __init__(self, block, in_channels, out_channels, n_blocks, stride=1):\n","    super().__init__()\n","    downsample = None\n","    if stride != 1 or in_channels != out_channels * block.expansion:\n","      downsample = nn.Sequential(nn.Conv2d(in_channels, \n","                                           out_channels * block.expansion, \n","                                           kernel_size=1, stride=stride,\n","                                           bias=False),\n","                                 nn.BatchNorm2d(out_channels * block.expansion))\n","    layers = []\n","    layers.append(block(in_channels, out_channels, stride, downsample))\n","    in_channels = out_channels * block.expansion\n","    for _ in range(1, n_blocks):\n","      layers.append(block(in_channels, out_channels))\n","    self.blocks = nn.Sequential(*layers)\n","\n","  def forward(self, x):\n","\n","    x = self.blocks(x)\n","    \n","    return x"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V__D4b3EyMnw","executionInfo":{"status":"ok","timestamp":1616280871097,"user_tz":420,"elapsed":870,"user":{"displayName":"Ankur Manikandan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh0fa0EuPCtGNgVCRiY6GI5Mx7fAl2Eu7pPVBF4=s64","userId":"06805748719310856295"}},"outputId":"1eb8da15-33c9-4e3b-fd55-9b2213c62bfe"},"source":["resnet_layer1 = ResNetLayer(BasicBlock, 64, 64, 3)\n","resnet_layer1"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ResNetLayer(\n","  (blocks): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (2): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xUB-PE1oyRM7","executionInfo":{"status":"ok","timestamp":1616280871098,"user_tz":420,"elapsed":850,"user":{"displayName":"Ankur Manikandan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh0fa0EuPCtGNgVCRiY6GI5Mx7fAl2Eu7pPVBF4=s64","userId":"06805748719310856295"}},"outputId":"a4f19f02-44bb-46da-968b-4c2f38074e4b"},"source":["resnet_layer2 = ResNetLayer(BottleneckBlock, 64, 128, 4, stride=2)\n","resnet_layer2"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ResNetLayer(\n","  (blocks): Sequential(\n","    (0): BottleneckBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BottleneckBlock(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (2): BottleneckBlock(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (3): BottleneckBlock(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"tPJIIZTyygGO"},"source":["# Define ResNet model\n","\n","We have defined the key elements of the ResNet model. Now, we will piece together the different elements to define the ResNet model architecture."]},{"cell_type":"code","metadata":{"id":"wLW0hB4pydCZ","executionInfo":{"status":"ok","timestamp":1616280871099,"user_tz":420,"elapsed":835,"user":{"displayName":"Ankur Manikandan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh0fa0EuPCtGNgVCRiY6GI5Mx7fAl2Eu7pPVBF4=s64","userId":"06805748719310856295"}}},"source":["class ResNet(nn.Module):\n","  def __init__(self, block, layers, n_classes):\n","    super().__init__()\n","    self.n_filters = 64\n","    # Define the convolution block\n","    self.conv1 = nn.Conv2d(3, self.n_filters, kernel_size=7, stride=2, padding=3, \n","                           bias=False)\n","    self.bn1 = nn.BatchNorm2d(self.n_filters)\n","    self.relu = nn.ReLU(inplace=True)\n","    self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","\n","    # Define the layers\n","    self.layer1 = ResNetLayer(block, self.n_filters, 64, layers[0])\n","    self.layer2 = ResNetLayer(block, 64 * block.expansion, 128, \n","                              layers[1], stride=2)\n","    self.layer3 = ResNetLayer(block, 128 * block.expansion, 256, \n","                              layers[2], stride=2)\n","    self.layer4 = ResNetLayer(block, 256 * block.expansion, 512, \n","                              layers[3], stride=2)\n","\n","    # Average of activations across a convolutional grid\n","    self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n","    # Final fully connected layer\n","    self.fc = nn.Linear(512 * block.expansion, n_classes)\n","\n","  def forward(self, x):\n","\n","    x = self.conv1(x)\n","    x = self.bn1(x)\n","    x = self.relu(x)\n","    x = self.maxpool(x)\n","    x = self.layer1(x)\n","    x = self.layer2(x)\n","    x = self.layer3(x)\n","    x = self.layer4(x)\n","    x = self.avg_pool(x)\n","    x = torch.flatten(x, 1)\n","    x = self.fc(x)\n","\n","    return x"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"h4mYRNKcyoMg","executionInfo":{"status":"ok","timestamp":1616280871100,"user_tz":420,"elapsed":825,"user":{"displayName":"Ankur Manikandan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh0fa0EuPCtGNgVCRiY6GI5Mx7fAl2Eu7pPVBF4=s64","userId":"06805748719310856295"}}},"source":["def resnet(name='resnet50', n_classes=1000):\n","\n","  if name == 'resnet18':\n","    layers = [2, 2, 2, 2]\n","    block = BasicBlock\n","  elif name == 'resnet34':\n","    layers = [3, 4, 6, 3]\n","    block = BasicBlock\n","  elif name == 'resnet50':\n","    layers = [3, 4, 6, 3]\n","    block = BottleneckBlock\n","  elif name == 'resnet101':\n","    layers = [3, 4, 23, 3]\n","    block = BottleneckBlock\n","  elif name == 'resnet152':\n","    layers = [3, 8, 36, 3]\n","    block = BottleneckBlock\n","\n","  # Initialize seed for repeatability\n","  torch.manual_seed(SEED)\n","\n","  # Call the model\n","  model = ResNet(block, layers, n_classes)\n","  \n","  return model"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NlON_jgKz5aI"},"source":["# Check if our implementation matches the ResNet models available via Torch Vision"]},{"cell_type":"markdown","metadata":{"id":"B4vemVHG0Dh8"},"source":["## ResNet-18"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"prv604M2zwUB","executionInfo":{"status":"ok","timestamp":1616280871529,"user_tz":420,"elapsed":1238,"user":{"displayName":"Ankur Manikandan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh0fa0EuPCtGNgVCRiY6GI5Mx7fAl2Eu7pPVBF4=s64","userId":"06805748719310856295"}},"outputId":"217cbd8a-9469-455c-d084-d1f4a5e58e94"},"source":["resnet18_model = resnet('resnet18', n_classes=1000)\n","print(\"Number of parameters in our ResNet-18 model:\", sum(np.prod(parameters.shape)\n","  for parameters in resnet18_model.parameters()))\n","print(\"Number of parameters in PyTorch ResNet-18 model:\", sum(np.prod(parameters.shape)\n","  for parameters in models.resnet18(False).parameters()))"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Number of parameters in our ResNet-18 model: 11689512\n","Number of parameters in PyTorch ResNet-18 model: 11689512\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"SoyDtyKB0ovX"},"source":["## ResNet-34"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rXCwX5oI0ovb","executionInfo":{"status":"ok","timestamp":1616280872323,"user_tz":420,"elapsed":2010,"user":{"displayName":"Ankur Manikandan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh0fa0EuPCtGNgVCRiY6GI5Mx7fAl2Eu7pPVBF4=s64","userId":"06805748719310856295"}},"outputId":"fa15a921-12a4-4b5d-dc09-a61262e9c574"},"source":["resnet34_model = resnet('resnet34', n_classes=1000)\n","print(\"Number of parameters in our ResNet-34 model:\", sum(np.prod(parameters.shape)\n","  for parameters in resnet34_model.parameters()))\n","print(\"Number of parameters in PyTorch ResNet-34 model:\", sum(np.prod(parameters.shape)\n","  for parameters in models.resnet34(False).parameters()))"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Number of parameters in our ResNet-34 model: 21797672\n","Number of parameters in PyTorch ResNet-34 model: 21797672\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yZZHgznm02Sr"},"source":["## ResNet-50"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1o7Bvmml02Ss","executionInfo":{"status":"ok","timestamp":1616280873036,"user_tz":420,"elapsed":2700,"user":{"displayName":"Ankur Manikandan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh0fa0EuPCtGNgVCRiY6GI5Mx7fAl2Eu7pPVBF4=s64","userId":"06805748719310856295"}},"outputId":"aa976c7e-a2bd-4a10-e569-6614dfe3a7ca"},"source":["resnet50_model = resnet('resnet50', n_classes=1000)\n","print(\"Number of parameters in our ResNet-50 model:\", sum(np.prod(parameters.shape)\n","  for parameters in resnet50_model.parameters()))\n","print(\"Number of parameters in PyTorch ResNet-50 model:\", sum(np.prod(parameters.shape)\n","  for parameters in models.resnet50(False).parameters()))"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Number of parameters in our ResNet-50 model: 25557032\n","Number of parameters in PyTorch ResNet-50 model: 25557032\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pqzdUMCt04KZ"},"source":["## ResNet-101"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"At-ua0ZH04Ka","executionInfo":{"status":"ok","timestamp":1616280874363,"user_tz":420,"elapsed":4004,"user":{"displayName":"Ankur Manikandan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh0fa0EuPCtGNgVCRiY6GI5Mx7fAl2Eu7pPVBF4=s64","userId":"06805748719310856295"}},"outputId":"a20de4cb-ac77-4fff-8423-e676e7b0c199"},"source":["resnet101_model = resnet('resnet101', n_classes=1000)\n","print(\"Number of parameters in our ResNet-101 model:\", sum(np.prod(parameters.shape)\n","  for parameters in resnet101_model.parameters()))\n","print(\"Number of parameters in PyTorch ResNet-101 model:\", sum(np.prod(parameters.shape)\n","  for parameters in models.resnet101(False).parameters()))"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Number of parameters in our ResNet-101 model: 44549160\n","Number of parameters in PyTorch ResNet-101 model: 44549160\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Mn1Rdd9x07kn"},"source":["## ResNet-152"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rnqoJAMk07ko","executionInfo":{"status":"ok","timestamp":1616280876118,"user_tz":420,"elapsed":5741,"user":{"displayName":"Ankur Manikandan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh0fa0EuPCtGNgVCRiY6GI5Mx7fAl2Eu7pPVBF4=s64","userId":"06805748719310856295"}},"outputId":"3516d9dc-91f0-4ab6-de04-4525623dce2c"},"source":["resnet152_model = resnet('resnet152', n_classes=1000)\n","print(\"Number of parameters in our ResNet-152 model:\", sum(np.prod(parameters.shape)\n","  for parameters in resnet152_model.parameters()))\n","print(\"Number of parameters in PyTorch ResNet-152 model:\", sum(np.prod(parameters.shape)\n","  for parameters in models.resnet152(False).parameters()))"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Number of parameters in our ResNet-152 model: 60192808\n","Number of parameters in PyTorch ResNet-152 model: 60192808\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JhUGrvZt1Y2f"},"source":["# References\n","\n","[1] [Deep Residual Learning for Image Recognition](https://arxiv.org/pdf/1512.03385.pdf)\n","\n","[2] [Torch Vision - ResNet](https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py)\n","\n","[3] [Convolutional Neural Networksâ€™ mathematics](https://towardsdatascience.com/convolutional-neural-networks-mathematics-1beb3e6447c0)\n","\n","[4] [ResNet, torchvision, bottlenecks, and layers not as they seem.](https://erikgaas.medium.com/resnet-torchvision-bottlenecks-and-layers-not-as-they-seem-145620f93096)\n","\n","[5] [Residual Networks: Implementing ResNet in Pytorch](https://towardsdatascience.com/residual-network-implementing-resnet-a7da63c7b278)\n","\n","[6] [Understanding and Building Resnet from scratch using Pytorch.](https://jarvislabs.ai/blogs/resnet)\n","\n","[7] [Building ResNet34 in PyTorch](https://github.com/jarvislabsai/blog/blob/master/build_resnet34_pytorch/Building%20Resnet%20in%20PyTorch.ipynb)"]}]}